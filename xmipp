#!/usr/bin/env python3
# ***************************************************************************
# * Authors:     Carlos Oscar S. Sorzano (coss@cnb.csic.es)
# *              David Maluenda (dmaluenda@cnb.csic.es)
# *
# *
# * This program is free software; you can redistribute it and/or modify
# * it under the terms of the GNU General Public License as published by
# * the Free Software Foundation; either version 2 of the License, or
# * (at your option) any later version.
# *
# * This program is distributed in the hope that it will be useful,
# * but WITHOUT ANY WARRANTY; without even the implied warranty of
# * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# * GNU General Public License for more details.
# *
# * You should have received a copy of the GNU General Public License
# * along with this program; if not, write to the Free Software
# * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
# * 02111-1307  USA
# *
# *  All comments concerning this program package may be sent to the
# *  e-mail address 'scipion@cnb.csic.es'
# ***************************************************************************/


import os
import re
import shutil
import sys
from datetime import datetime
from scripts import *


# ----K-E-E-P----U-P-D-A-T-E-D---- #
####################################
XMIPP_VERSION = '3.22.04.0'        #
XMIPP_VERNAME = 'Gaia'           #
RELEASE_DATE = '21/04/2022'        #
####################################


XMIPP = 'xmipp'
XMIPP_CORE = 'xmippCore'
XMIPP_VIZ = 'xmippViz'
SCIPION_EM_XMIPP = 'scipion-em-xmipp'
CUFFTADVISOR = 'cuFFTAdvisor'
CTPL = 'CTPL'
GTEST = 'googletest'
LIBSVM = 'libsvm'

REPOSITORIES = {XMIPP: 'https://github.com/I2PC/xmipp.git',
                XMIPP_CORE: 'https://github.com/I2PC/xmippCore.git',
                XMIPP_VIZ: 'https://github.com/I2PC/xmippViz.git',
                SCIPION_EM_XMIPP: 'https://github.com/I2PC/scipion-em-xmipp.git',
                CUFFTADVISOR: 'https://github.com/DStrelak/cuFFTAdvisor.git',
                CTPL: 'https://github.com/vit-vit/CTPL.git',
                GTEST: 'https://github.com/google/googletest',
                LIBSVM: 'https://github.com/cossorzano/libsvm.git'}

#              {dep-repo:     (branch, check-conf)}
DEPENDENCIES = {CUFFTADVISOR: ('master', 'CUDA'),
                CTPL: ('master', None),
                GTEST: ('release-1.10.0', Config.KEY_BUILD_TESTS),
                LIBSVM: ('master', None)}

# if a skippable compilation fails (if 'key' found in the failed code),
# a hint is printed in order to export 'value' or edit the config file
SKIPPABLE_BINS = {"optical_alignment": "OPENCV=False",
                  "volume_homogenizer": "OPENCV=False",
                  "cuda": "CUDA=False"}

XMIPP_ENV = {}


def checkGithubConnection():
    from http.client import HTTPConnection
    from socket import gaierror
    conn = HTTPConnection("www.github.com", timeout=3)
    try:
        conn.request("HEAD", "/")
        return True
    except gaierror:
        return False
    finally:
        conn.close()


def stampVersion():
    LAST_COMPILATION = datetime.now().strftime("%d/%m/%Y")

    def getCommit(repo):
        """ In devel mode 'commit.info' should not exist.
            In production mode 'commit.info' is added by tar.py
        """
        commitFn = os.path.join('src', repo, 'commit.info')
        notFoundInfo = "(no git repo detected)"
        if os.path.isfile(commitFn):
            with open(commitFn, 'r') as file:
                commitInfo = file.readline()
        elif ensureGit(False):
            found, br, hsh = getCurrentBranch(os.path.join('src', repo),
                                              getHash=True)
            commitInfo = "%s (%s)" % (br, hsh) if found else notFoundInfo
        else:
            commitInfo = notFoundInfo

        return commitInfo

    compilingInfo = {'XMIPP_VERSION': XMIPP_VERSION,
                     'RELEASE_DATE': RELEASE_DATE,
                     'XMIPP_BRANCH': getCommit(XMIPP),
                     'PLUGIN_BRANCH': getCommit(SCIPION_EM_XMIPP),
                     'CORE_BRANCH': getCommit(XMIPP_CORE),
                     'VIZ_BRANCH': getCommit(XMIPP_VIZ),
                     'LAST_COMPILATION': LAST_COMPILATION,
                     'XMIPP_VERNAME': XMIPP_VERNAME
                     }

    versionBinFn = os.path.join('src', 'xmipp', 'applications', 'programs',
                                'version', 'version.cpp')
    createDir(os.path.dirname(versionBinFn))
    with open(versionBinFn, 'w') as f:
        f.write("""// Auto-generated code to get compilation Info
#include <sys/utsname.h>
#include <iostream>
#include <string.h>
using namespace std;

int main(int argc, char** argv){

    if (argc>2)
    {
        std::cout << "Incorrect parameter" << std::endl;
        return 1;
    }
    int shrt = 0;
    if (argc>1)
    {
        if((strcmp(argv[1], "--short") == 0))
        {
            shrt = 1;
        }else{
            std::cout << "Incorrect parameter: " << argv[1] << std::endl;
            return 2;
        }
    }

    if (shrt==1)
    {
        std::cout << "%(XMIPP_VERSION)s" << std::endl;
    }else{
        struct utsname utsname; // stores the data returned by uname()
        struct utsname *utsname_ptr = &utsname; // pointer to the struct holding the data returned by uname()
    
        int ret;
        ret = uname(utsname_ptr);
    
        std::cout << std::endl;
        std::cout << "  \033[4mXmipp version\033[24m: \033[1m%(XMIPP_VERSION)s (%(XMIPP_VERNAME)s)\033[0m" << std::endl;
        std::cout << std::endl;
        std::cout << "  Release date:     %(RELEASE_DATE)s" << std::endl;
        std::cout << "  Xmipp branch:     %(XMIPP_BRANCH)s" << std::endl;
        std::cout << "  Plugin branch:    %(PLUGIN_BRANCH)s" << std::endl;
        std::cout << "  Core branch:      %(CORE_BRANCH)s" << std::endl;
        std::cout << "  Viz branch:       %(VIZ_BRANCH)s" << std::endl;
        std::cout << "  Compilation date: %(LAST_COMPILATION)s" << std::endl;
        std::cout << "  Compiler:         g++ " << __VERSION__ << std::endl;
        std::cout << "  Compiling system: " << utsname.machine << " " << utsname.sysname
                  << " " << utsname.release << std::endl 
                  << "                    " << utsname.version << std::endl;
        std::cout << std::endl;
    }
    return 0;
}
""" % compilingInfo)


def createDir(dirname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)


def cleanSources():
    for dep in DEPENDENCIES.keys():
        runJob("rm -rf src/%s" % dep)
    runJob("rm -rf src/scipion-em-xmipp")
    runJob("rm -rf src/xmippCore")
    runJob("rm -rf src/xmippViz")
    runJob("rm -rf src/xmipp/bin")
    runJob("rm -rf src/xmipp/lib")
    runJob("rm -rf src/xmipp/.sconsign.dblite")
    if ensureGit(False):
        runJob("git stash")  # to get exactly like in repo


def cleanBinaries():
    for ext in ['so', 'os', 'o']:
        runJob('find src/* -name "*.%s" -exec rm -rf {} \;' % ext)
    runJob('find . -iname "*.pyc" -delete')
    runJob("rm -rf %s build" % Config.FILE_NAME)
    # I'm getting ValueError : unsupported pickle protocol: 5' when switching from one python version to another
    # This seems to be cached at dblite file.
    runJob('find . -iname "*.dblite" -delete')


def checkout(branch):
    r, currentBranch = getCurrentBranch()
    if currentBranch == branch:
        return True
    if isRepositoryClean() and runJob("git checkout %s" % branch):
        return True
    print(red("Cannot checkout branch '%s'. Remaining on the branch '%s'." % (branch, currentBranch)))
    return False


def isRepositoryClean(showError=True):
    log = []
    runJob('git diff --name-only', show_output=False, show_command=False, log=log)
    if showError and log: # non-empty log means there are uncommited changes
        print(red('Repository contains uncommitted changes.'))
        print(red("Use 'compileAndInstall' mode to keep developing."))
    return not log


def pull():
    log=[]
    isRemoteBranch = runJob('git rev-parse HEAD@{upstream}', show_command=False, show_output=False, log=log)
    if not isRemoteBranch:
        print(yellow(str('Git info: ' + log[0])))
    if checkGithubConnection() and isRemoteBranch:
        return runJob("git pull", show_command=False)
    return True  # meaning that this is a local branch or we are offline, so pull doesn't make sense


def cloneOrCheckout(repo, branch):
    repo_dir = os.path.join('src', repo) if repo != XMIPP else '.'
    if branch not in getAllBranchesAndTags(repo)[1]:
        branch = getBranch(repo, repo_dir)[1]

    if not os.path.exists(repo_dir):
        # If the repo doesn't exist, just clone the whole repo
        if branch is None:
            # let the git client to decide what is the default branch
            return runJob("git clone %s %s" % (REPOSITORIES[repo], repo_dir))
        else:
            return runJob("git clone -b %s %s %s" % (branch, REPOSITORIES[repo], repo_dir))
    else:
        workDir = os.getcwd()
        os.chdir(repo_dir)
        print(green('Checkouting %s:%s ...' % (repo, branch)))
        res = checkout(branch) and pull()
        os.chdir(workDir)
        return res


def removePrefix(text, prefix):
    if text.startswith(prefix):
        return text[len(prefix):]
    return text


def getCurrentCIBranch():
    # see https://docs.travis-ci.com/user/environment-variables/
    # see https://docs.github.com/en/actions/reference/environment-variables#default-environment-variables
    # On Travis, PR will have the TRAVIS_PULL_REQUEST_BRANCH variable non-empty
    # otherwise the TRAVIS_BRANCH will hold the name of the current branch
    # On Github Actions, GITHUB_REF will hold either the tag or branch (including prefix) to the branch which triggered 
    # the workflow
    # For pull request, GITHUB_HEAD_REF will be set (no prefix)
    current_branch = (
        os.environ.get('TRAVIS_PULL_REQUEST_BRANCH') or
        os.environ.get('TRAVIS_BRANCH') or
        os.environ.get('GITHUB_HEAD_REF') or
        os.environ.get('GITHUB_REF'))
    current_branch = removePrefix(current_branch, 'refs/heads/')
    current_branch = removePrefix(current_branch, 'refs/tags/')
    print(green("Detected branch: " + current_branch))
    return current_branch is not None, current_branch


def getCurrentBranch(cwd='./', getHash=False):
    """ If getHash=True:  return (success, branch, hash)
        If getHash=False: return (success, branch)
    """
    outBranchArgs = 2 if getHash else 1
    log = []
    commit = []
    if not os.path.exists(cwd) or not runJob('git rev-parse --short HEAD',
                                             cwd=cwd, show_output=False,
                                             show_command=False, log=commit):
        return (False,) + (None,)*outBranchArgs
    result = runJob('git name-rev ' + commit[0], cwd=cwd, show_output=False,
           show_command=False, log=log)
    if result:  # log contains commit_space_branchName
        return (True,) + tuple(log[0].split()[::-1][0:outBranchArgs])
    print(red('Cannot list branches for ' + ''.join(log)))
    return (False,) + (None,)*outBranchArgs


def getAllBranchesAndTags(repo):
    log = []
    result = runJob('git ls-remote -t -h %s' % REPOSITORIES[repo],
                    show_output=False, log=log, show_command=False)
    if result:
        branchesAndTags = [l.split('/')[-1] for l in log]
        return True, branchesAndTags
    print(red('Cannot list branches for ' + repo + ''.join(log)))
    return False, None


def getBranch(repo, repo_dir):
    # return current branch
    r, branch = getCurrentBranch(repo_dir)
    if r:
        return r, branch
    # return same branch as xmipp
    # we need to get current branch of the xmipp
    r1, branchHint = (getCurrentCIBranch() if isCIBuild()
                      else getCurrentBranch())
    r2, branches = getAllBranchesAndTags(repo)
    if r1 and r2 and branchHint in branches:
        return True, branchHint
    # default branch
    return getDefaultBranch(repo)


def getDefaultBranch(repo):
    log = []
    key = 'HEAD branch:'
    # this might not work for git < 1.8.5,
    # see https://stackoverflow.com/a/32503667/5484355
    # and https://stackoverflow.com/questions/2832269/git-remote-head-is-ambiguous
    # In such a case we return None (and during e.g. clone the client should
    # decide what is the default branch)
    result = runJob('git remote show %s' % REPOSITORIES[repo],
                    show_output=False, log=log, show_command=False)
    if result:
        for l in log:
            if key in l:
                branch = l.split(key)[1] # HEAD branch: devel
                return (True, branch.strip())
    print(red('Cannot auto-detect default branch for ' + repo +
              '. Maybe git version < 1.8.5?\n' + ''.join(log)))
    return (False, None)


def getSources(branch):
    print("Getting sources -------------------------------------")
    ensureGit(True)
    createDir("src")
    repos = [XMIPP_CORE, XMIPP_VIZ, SCIPION_EM_XMIPP]
    if not isCIBuild():
        # do not change current commit
        repos.append(XMIPP)
    for r in repos:
        if not cloneOrCheckout(r, branch):
            print(red("Cannot get the sources"))
            return False
    return True


def getDependencies():
    print("Getting Dependencies -------------------------------------")
    ensureGit(True)
    createDir("src")
    result = True
    for dep, args in DEPENDENCIES.items():
        branch = args[0]
        configChecked = not args[1] or buildConfig.is_true(args[1])
        if configChecked and result:
            result = cloneOrCheckout(dep, branch)
    if not result:
        print(red("Cannot get dependencies"))
    return result


def getScipionHome():
    """ Returns SCIPION_HOME, the directory for scipion3 or EMPTY str. """
    return os.environ.get("SCIPION_HOME", whereis("scipion3")) or ''


def compileModule(Nproc,module):
    if module == "xmipp":
        stampVersion()
    log = []
    ok = runJob("/usr/bin/env python3 $(which scons) -j%s" % Nproc, "src/%s" % module, log=log)
    if not ok:
        failingBin = None
        for l in log[-30:]:  # inspecting last 30 lines
            # expected error: 'scons: *** [some/program/to/compile] Error 1'
            errorRegex = re.match("scons: \*\*\* \[(.*)\] (.*Error) ([0-9]*)[: ]*(.*)", l)
            if errorRegex:
                failingBin = errorRegex.group(1)
                errorType = errorRegex.group(2)
                errorNum = errorRegex.group(3)
                errorMsg = errorRegex.group(4)
                for k, v in SKIPPABLE_BINS.items():
                    if k in failingBin:
                        print(red("\nSome error found compiling '%s' program."
                                  % failingBin.split('/')[-1]))
                        print(red("You can skip this program by including '%s' "
                                  "in the config file." % (v)))
                if 'unsupported pickle protocol' in errorMsg:
                    print(red("\nThis error might be because you changed the python "
                              "version. If so, please run './xmipp cleanBin' to "
                              "clean up the installation and, then './xmipp' to "
                              "re-compile it."))
            errorRegex = re.match(".*: fatal error: (.*): No such file or directory", l)
            if errorRegex:
                missingPath = errorRegex.group(1)
                print(red("\n'%s' file not found." % missingPath))
                missingDir = missingPath.split(os.path.sep)[0]
                missingFile = os.path.join(*missingPath.split(os.path.sep)[1:])
                if missingDir in DEPENDENCIES.keys():
                    depDir = os.path.join('src', missingDir)
                    hint = ('cd %s ; git checkout -- %s ; cd -' % (depDir, missingFile)
                            if os.path.isdir(depDir) else './xmipp get_dependencies')
                    print(red("This file belongs to %s dependency. Please, "
                              "try '%s' and re-compile." % (missingDir, hint)))
        print(red("\nSome error occurred during the compilation of '%s'%s.\n"
                  % (module, (" ('%s')" % failingBin) if failingBin else '')))
        sys.exit(1)
    return ok


def compile_cuFFTAdvisor():
    advisorDir = "src/cuFFTAdvisor/"
    currDir = os.getcwd()
    libDir = "src/xmipp/lib/"
    createDir(libDir)
    os.chdir(advisorDir)
    ok = runJob("make all")
    os.chdir(currDir)
    return ok and runJob("cp " + advisorDir + "build/libcuFFTAdvisor.so" + " " + libDir)


def compile_googletest():
    currDir = os.getcwd()
    buildDir = os.path.join("src", "googletest", "build")
    createDir(buildDir)
    os.chdir(buildDir)
    ok = runJob("cmake ..")
    ok = ok and runJob("make gtest gtest_main")
    os.chdir(currDir)
    return ok


def compile_libsvm():
    #if the libsvm repo is updated, remember that the repoFork/Makefile was edited to remove references to libsvm-so.2
    currDir = os.getcwd()
    libsvmDir = os.path.join("src", "libsvm")
    os.chdir(libsvmDir)
    ok = runJob("make lib")
    libDir = "src/xmipp/lib"
    os.chdir(currDir)
    createDir(libDir)
    ok = ok and runJob("cp " + libsvmDir + "/libsvm.so" + " " + libDir)
    return ok


def compile(Nproc):
    if isinstance(Nproc, str) and Nproc.startswith('N='):
        Nproc = int(Nproc.split('N=')[1])
    buildConfig.check_version()
    if not compileDependencies(Nproc):
        return False
    return compileXmipp(Nproc)


def compileDependencies(Nproc):
    print("Building Dependencies -------------------------------------")
    result = True
    if buildConfig.is_true('CUDA'):
        cudaBinDir, nvccBaseName = os.path.split(buildConfig.get()['NVCC'])
        # cuFFTAdvisor compilation needs 'nvcc' accessible through the PATH
        if not checkProgram(nvccBaseName, False) and checkProgram(buildConfig.get()['NVCC'], False):
            # if nvcc basename is not found but absolute path yes, adding the dir to the path.
            os.environ['PATH'] = os.pathsep.join([cudaBinDir, os.environ['PATH']])
        result = result and (checkProgram('make', True) or installDepConda('make'))
        result = result and compile_cuFFTAdvisor()
    if buildConfig.is_true(Config.KEY_BUILD_TESTS):
        result = result and compile_googletest()
    result = result and compile_libsvm()
    if not result:
        print(red("Cannot build dependencies"))
    return result


def compileXmipp(Nproc):
    print("Compiling -------------------------------------------")
    if not compileModule(Nproc,"xmippCore"):
        return False
    if not compileModule(Nproc,"xmipp"):
        return False
    if not compileModule(Nproc,"xmippViz"):
        return False
    return True


def runTests(testNames):
    if len(testNames)==0 or 'help' in testNames or '--help' in testNames:
        print("Usage: xmipp test op\n"
              "\n"
              "         op = --show: Show how to invoke all available tests\n"
              "              --allPrograms: Run all program tests\n"
              "              --allFuncs: Run all function tests\n"
              "              'testName': Run certain test (more than one is available)."
              "\n")
        return

    print("Testing ---------------------------------------------")

    xmippSrc = os.environ.get('XMIPP_SRC', None)
    if xmippSrc and os.path.isdir(xmippSrc):
        os.environ['PYTHONPATH'] = ':'.join([
            os.path.join(os.environ['XMIPP_SRC'], XMIPP),
            os.environ.get('PYTHONPATH', '')])

        testsPath = os.path.join(os.environ['XMIPP_SRC'], XMIPP, 'tests')
    else:
        print(red('XMIPP_SRC is not in the enviroment.') +
              '\nTo run the tests you need to run: ' +
              blue('source build/xmipp.bashrc'))
        sys.exit(1)

    dataSetPath = os.path.join(testsPath, 'data')
    # if not os.path.isdir(dataSetPath):
    #     createDir(dataSetPath)
    os.environ["XMIPP_TEST_DATA"] = dataSetPath

    # downloading/updating the dataset
    url = "http://scipion.cnb.csic.es/downloads/scipion/data/tests"
    dataset = 'xmipp_programs'
    if os.path.isdir(dataSetPath):
        print(blue("Updating the test files"))
        task = "update"
    else:
        print(blue("Downloading the test files"))
        task = "download"
    args = "%s %s %s" % ("tests/data", url, dataset)
    runJob("bin/xmipp_sync_data %s %s" % (task, args), cwd='src/xmipp')

    noCudaStr = '--noCuda' if not buildConfig.is_true('CUDA') else ''
    print(" Tests to do: %s" % ', '.join(testNames))
    if not runJob("(cd src/xmipp/tests; %s test.py %s %s)"
                  % (getPython(), ' '.join(testNames), noCudaStr)):
        sys.exit(-1)


def getPython():
    if checkProgram("scipion3", False):
        return "scipion3 python"
    else:
        return 'python3'


def addDeepLearninModel(login, modelPath='', update=None):
    """ Takes the folder name modelName from models dir and
        makes a .tgz, uploads the .tgz to scipion web.
    """
    def usageDL():
        print("""
        XMIPP addModel help:
        
        This mode is used to upload a model folder to the Scipion/Xmipp server.
        Usually the model folder contains big files used to fed deep learning procedures
        with pretrained data. All the models stored in the server will be downloads
        using the 'get_models' mode or during the compilation/installation time
        if 'USE_DL=True' in the config file. [or with 'scipion3 installb deepLearningToolkit']
        
        Usage: -> ./xmipp addModel <usr@server> <modelsPath> [--update]
        
        Behaviour: 0. modelName = basename(modelsPath) <- Please, check the folder's name!
                   1. Packing in 'xmipp_model_modelName.tgz'
                   2. Check if that model already exists (use --update to override an existing model)
                   3. Upload the model to the server.
                   4. Update the MANIFEST file.
                   
        The model name will be the folder name in <modelsPath>
        """)
        sys.exit(0)

    if login == '--help':
        usageDL()

    modelPath = modelPath.rstrip("/")
    if not os.path.isdir(modelPath):
        print("<modelsPath> is not a directory. Please, check the path. \n"
              "The name of the model will be the name of that folder.\n")
        usageDL()

    modelName = os.path.basename(modelPath)
    modelsDir = os.path.dirname(modelPath)
    tgzFn = "xmipp_model_%s.tgz" % modelName
    localFn = os.path.join(modelsDir, tgzFn)

    print("Creating the '%s' model." % tgzFn)
    runJob("tar czf %s %s" % (tgzFn, modelName), cwd=modelsDir)

    remotePath = "scipionfiles/downloads/scipion/software/em"
    print("Warning: Uploading, please BE CAREFUL! This can be dangerous.")
    print('You are going to be connected to "%s" to write in folder '
           '"%s".' % (login, remotePath))
    if input("Continue? YES/no\n").lower() == 'no':
        sys.exit()

    print("Trying to upload the model using '%s' as login" % login)
    args = "%s %s %s %s" % (login, os.path.abspath(localFn), remotePath, update)
    if runJob("src/xmipp/bin/xmipp_sync_data upload %s" % args):
        print("'%s' model successfully uploaded! Removing the local .tgz"
              % modelName)
        runJob("rm %s" % localFn)


pDLdownload = None
def downloadDeepLearningModels(dest, dedicatedMode=False):
    if not buildConfig.is_true('USE_DL') and not dedicatedMode:
        return True
    url = "http://scipion.cnb.csic.es/downloads/scipion/software/em"

    if dest == 'build':
        modelsPath = os.path.join(dest, 'models')
    else:
        modelsPath = dest
    dataSet = "DLmodels"

    # downloading/updating the DLmodels
    if os.path.isdir(modelsPath):
        print("Updating the Deep Learning models (in backgound)")
        task = "update"
    else:
        print("Downloading Deep Learning models (in backgound)")
        task = "download"
    global pDLdownload

    # using Popen instead of runJob in order to download in parallel
    pDLdownload = runJob("bin/xmipp_sync_data %s %s %s %s"
                         % (task, dest, url, dataSet),
                         cwd='build', show_command=False,
                         in_parallel=not dedicatedMode)
    if dedicatedMode:
        ok = pDLdownload
    else:  # in parallel poll() is None untill finished
        ok = pDLdownload.poll() is None or pDLdownload.poll() == 0
    return ok


def linkToScipion(dirname):
    scipionSoftware = os.environ.get('SCIPION_SOFTWARE',
                                     os.path.join(getScipionHome(), 'software'))
    scipionLibs = os.path.join(scipionSoftware, 'lib')
    scipionBindings = os.path.join(scipionSoftware, 'bindings')
    scipionSoftwareEM = os.path.join(scipionSoftware, 'em')
    xmippHomeLink = os.path.join(scipionSoftwareEM, 'xmipp')
    currentDir = os.getcwd()
    dirnameAbs = os.path.join(currentDir,dirname)
    if os.path.isdir(scipionLibs) and os.path.isdir(scipionBindings):
        print("Linking to Scipion ------------------------------------------")
        if os.path.isdir(xmippHomeLink):
            runJob("rm %s" %xmippHomeLink)
        runJob("ln -srf %s %s" % (dirnameAbs, xmippHomeLink))
        xmippLink = os.readlink(xmippHomeLink)
        coreLib = os.path.join(xmippLink, "lib", "libXmippCore.so")
        xmippLib = os.path.join(xmippLink, "lib", "libXmipp.so")
        SVMLib = os.path.join(xmippLink, "lib", "libsvm.so")
        bindings = os.path.join(xmippLink, "bindings", "python", "*")

        os.chdir(scipionSoftwareEM)
        runJob("ln -srf %s %s" % (coreLib, scipionLibs))
        runJob("ln -srf %s %s" % (SVMLib, scipionLibs))
        runJob("ln -srf %s %s" % (xmippLib, scipionLibs))
        runJob("ln -srf %s %s" % (bindings, scipionBindings))
        os.chdir(currentDir)
        print(green(str("xmipp Link for Scipion: " + xmippHomeLink)))
        print(green("Xmipp linked to Scipion3"))

    else:
        print(yellow("No scipion3 found. If you intended to use Xmipp in "
                     "the Scipion framework:\ncompile Xmipp "
                     "with Scipion './scipion3 run ./xmipp' or check the binding at "
                     "SCIPION_HOME/software/bindings..."))


def install(dirname):
    print("Installing ------------------------------------------")
    cpCmd = "rsync -LptgoD" if checkProgram("rsync", False) else "cp"
    ok = True

    createDir(dirname)

    createDir(dirname+"/lib")
    ok = ok and runJob(cpCmd+" src/*/lib/lib* "+dirname+"/lib/")

    createDir(dirname+"/bin")
    ok = ok and runJob(cpCmd+" src/*/bin/* "+dirname+"/bin/")

    destPathPyModule = os.path.expanduser(os.path.abspath(os.path.join(dirname, "pylib", "xmippPyModules")))
    createDir(destPathPyModule)
    initFn = destPathPyModule + "/__init__.py"
    if not os.path.isfile(initFn):
        with open(initFn, 'w') as f:
            pass  # just to create a init file to be able to import it as module

    runJob(cpCmd+" -r src/xmipp/libraries/py_xmipp/* "+destPathPyModule)

    createDir(dirname+"/bindings")
    createDir(dirname+"/bindings/matlab")
    ok = ok and runJob(cpCmd+" src/xmipp/bindings/matlab/*.m* "+dirname+"/bindings/matlab/")

    createDir(dirname+"/bindings/python")
    ok = ok and runJob(cpCmd+" src/xmipp/bindings/python/xmipp_base.py "+dirname+"/bindings/python/")
    ok = ok and runJob(cpCmd+" src/xmipp/bindings/python/xmipp.py " + dirname + "/bindings/python/")
    ok = ok and runJob(cpCmd+" src/xmipp/bindings/python/xmipp_conda_envs.py " + dirname + "/bindings/python/")
    ok = ok and runJob(cpCmd+" src/xmipp/lib/xmippLib.so "+dirname+"/bindings/python/")
    ok = ok and runJob(cpCmd+" src/xmipp/lib/_swig_frm.so "+dirname+"/bindings/python/")

    createDir(dirname+"/bindings/python/sh_alignment")
    ok = ok and runJob(cpCmd+" -r src/xmipp/external/sh_alignment/python/* "+dirname+"/bindings/python/sh_alignment/")
    ok = ok and runJob(cpCmd+" src/xmipp/external/sh_alignment/swig_frm.py "+dirname+"/bindings/python/sh_alignment/")

    createDir(dirname+"/resources")
    ok = ok and runJob(cpCmd+" -r src/*/resources/* "+dirname+"/resources/")

    # ok = ok and runJob(cpCmd + " -r src/xmippViz/bindings/chimera " + dirname + "/bindings/")
    createDir(dirname+"/bindings/java")
    ok = ok and runJob(cpCmd+" -Lr src/xmippViz/java/lib "+dirname+"/bindings/java/")
    ok = ok and runJob(cpCmd+" -Lr src/xmippViz/java/build "+dirname+"/bindings/java/")
    ok = ok and runJob(cpCmd+" -Lr src/xmippViz/external/imagej "+dirname+"/bindings/java/")
    ok = ok and runJob(cpCmd+" src/xmippViz/bindings/python/xmippViz.py "+dirname+"/bindings/python/")

    ok = ok and runJob(cpCmd+" xmippEnv.json "+dirname+"/xmippEnv.json")

    if not ok:
        print(red("\nSome error occurred during the installation.\n"))
        sys.exit(1)

    # Scipion connection
    linkToScipion(dirname)

    runJob("touch %s/v%s" % (dirname, XMIPP_VERSION))  # version token
    fhBash = open(dirname+"/xmipp.bashrc","w")
    fhFish = open(dirname+"/xmipp.fish","w")
    fhBash.write("# This script is valid for bash and zsh\n\n")
    fhFish.write("# This script is valid for fish\n\n")

    XMIPP_HOME = os.path.realpath(dirname)
    fhBash.write("export XMIPP_HOME=%s\n"%XMIPP_HOME)
    fhFish.write("set -x XMIPP_HOME %s\n"%XMIPP_HOME)

    XMIPP_SRC = os.path.realpath("src")
    fhBash.write("export XMIPP_SRC=%s\n"%XMIPP_SRC)
    fhFish.write("set -x XMIPP_SRC %s\n"%XMIPP_SRC)

    # SCIPION_HOME = getScipionHome()
    # if SCIPION_HOME:
    #     fhBash.write("export PATH=$SCIPION_HOME/software/bin:$PATH\n")
    #     fhBash.write("export LD_LIBRARY_PATH=$SCIPION_HOME/software/lib:$LD_LIBRARY_PATH\n")
    #     #fhFish.write("set -px PATH $SCIPION_HOME/software/bin\n")
    #     fhFish.write("set -px LD_LIBRARY_PATH $SCIPION_HOME/software/lib\n")
    virtEnvDir = os.environ.get('VIRTUAL_ENV', '')  # if virtualEnv is used
    virtEnvLib = os.path.join(virtEnvDir, 'lib') if virtEnvDir else ''
    condaDir = os.environ.get('CONDA_PREFIX', '')  # if conda is used
    condaLib = os.path.join(condaDir, 'lib') if condaDir else ''
    fhBash.write("export PATH=%s/bin:$PATH\n"%XMIPP_HOME)
    fhBash.write("export LD_LIBRARY_PATH=%s/lib:%s/bindings/python:%s:%s:$LD_LIBRARY_PATH\n"
                 %(XMIPP_HOME, XMIPP_HOME, virtEnvLib, condaLib))
    fhBash.write("export PYTHONPATH=%s/bindings/python:%s/pylib:$PYTHONPATH\n"%(XMIPP_HOME,XMIPP_HOME))
    fhFish.write("set -px PATH %s/bin\n"%XMIPP_HOME)
    fhFish.write("set -px LD_LIBRARY_PATH %s/lib %s/bindings/python %s %s\n"
                 %(XMIPP_HOME, XMIPP_HOME, virtEnvLib, condaLib))
    fhFish.write("set -px PYTHONPATH %s/bindings %s/pylib\n"%(XMIPP_HOME,XMIPP_HOME))   

    fhBash.write('\n')
    fhBash.write("alias x='xmipp'\n")
    fhBash.write("alias xsj='xmipp_showj'\n")
    fhBash.write("alias xio='xmipp_image_operate'\n")
    fhBash.write("alias xis='xmipp_image_statistics'\n")
    fhBash.write("alias xih='xmipp_image_header'\n")
    fhBash.write("alias xmu='xmipp_metadata_utilities'\n")
    fhFish.write('\n')
    fhFish.write("alias x 'xmipp'\n")
    fhFish.write("alias xsj 'xmipp_showj'\n")
    fhFish.write("alias xio 'xmipp_image_operate'\n")
    fhFish.write("alias xis 'xmipp_image_statistics'\n")
    fhFish.write("alias xih 'xmipp_image_header'\n")
    fhFish.write("alias xmu 'xmipp_metadata_utilities'\n")

    fhBash.close()
    fhFish.close()


    print("\n"
          "  ********************************************\n"
          "  *                                          *\n"
          "  * ", end='')
    print(green('Xmipp has been successfully installed!'), end='')
    print("  *\n"
          "  *                                          *\n"
          "  ********************************************\n\n")



    return True


def writeDevelPaths(dirname):
    fhBash = open(dirname+"/xmipp.bashrc","w")

    XMIPP_HOME = os.path.realpath(dirname)
    fhBash.write("export XMIPP_HOME=%s\n"%XMIPP_HOME)

    XMIPP_SRC = os.path.realpath("src")
    fhBash.write("export XMIPP_SRC=%s\n"%XMIPP_SRC)

    # SCIPION_HOME = getScipionHome()
    # if SCIPION_HOME:
    #     fhBash.write("export PATH=$SCIPION_HOME/bin:$PATH\n")
    #     fhBash.write("export LD_LIBRARY_PATH=$SCIPION_HOME/software/lib:$LD_LIBRARY_PATH\n")

    fhBash.write("export PATH=%s/xmipp/bin:%s/xmippViz/bin:$PATH\n"%(XMIPP_HOME,XMIPP_HOME))
    fhBash.write("export LD_LIBRARY_PATH=%s/xmippCore/lib:$LD_LIBRARY_PATH\n"%XMIPP_HOME)
    fhBash.write("export LD_LIBRARY_PATH=%s/xmippCore/bindings/python:$LD_LIBRARY_PATH\n"%XMIPP_HOME)
    fhBash.write("export LD_LIBRARY_PATH=%s/xmipp/lib:$LD_LIBRARY_PATH\n"%XMIPP_HOME)
    fhBash.write("export LD_LIBRARY_PATH=%s/xmipp/bindings/python:$LD_LIBRARY_PATH\n"%XMIPP_HOME)
    fhBash.write("export PYTHONPATH=%s/xmippCore/bindings/python:$PYTHONPATH\n"%XMIPP_HOME)
    fhBash.write("export PYTHONPATH=%s/xmipp/bindings/python:$PYTHONPATH\n"%XMIPP_HOME)
    fhBash.write("export PYTHONPATH=%s/xmippViz/bindings/python:$PYTHONPATH\n"%XMIPP_HOME)

    fhBash.close()


def usage(msg=''):
    if msg != '':
        print(red(msg))
    print("Usage: xmipp [options]\n"
          "   version [dir=build];        Returns the version information. Add '--short' to print only the version number.\n"
          "   all [op1=opt1 op2=opt2...]: (Default) Retrieve [br=branch], configure, check, compile [N=8], install [dir=build]\n"
          "   get_dependencies:           Retrieve dependencies from github\n"
          "   get_devel_sources [branch]: Retrieve development sources from github for a given branch (devel branch by default)\n"
          "   cleanBin:                   Clean all already compiled files (build, .so,.os,.o in src/* and " + Config.FILE_NAME + ")\n"
          "   cleanAll:                   Delete all (sources and build directories)\n"
          "   config [noAsk]:             Configure compilation variables. If 'noAsk' is passed, it will try to automatically found some libraries and compilers. \n"
          "                               for compiling using system libraries\n"
          "   check_config:               Check that the configuration is correct\n"
          "   compile [N]:                Compile with N processors (8 by default)\n"
          "   compileAndInstall [N] [dir] Compile with N processors (8 by default) and install in the dir directory ('build' by default)\n"
          "   install [dir]:              Install at dir (./build by default)\n"
          "   get_models [dir]:           Download the Deep Learning Models at dir/models (./build/models by default).\n"
          "   test [--show] testName:     Run tests to check Xmipp programs (without args, it shows a detailed help).\n"
          "                                 if --show is activated without testName all are shown, \n"
          "                                 instead a grep of testName is done \n"
          "For developers:\n"
          "   create_devel_paths:         Create bashrc files for devel\n"
          "   git ...:                    Git command to all 4 repositories\n"
          "   gitConfig:                  Change the git config from https to git\n"
          "   addModel login modelPath:   Takes a deepLearning model from the 'modelPath', makes a tgz of it and \n"
          "                                   uploads the .tgz according to the <login>. \n"
          "                                   Note the login (usr@server) must have write permisions to Nolan machine.\n"
          "   tar <mode> [v=ver] [br=br]: Create a bundle of the xmipp (without arguments shows a detailed help)\n"
          "                                   <mode> can be 'Sources', 'BinDebian' or 'BinCentos', when Sources put a branch (default: master).'\n"
          "                                   <ver> usually X.YY.MM (add debug to package this local script and the local scripts/tar.py) \n"
          )



if __name__ == '__main__':
    # Running always under this own directory.
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    askUser = True

    if 'noAsk' in sys.argv:
        askUser = False
        sys.argv.pop(sys.argv.index('noAsk'))

    n = len(sys.argv)
    if n == 2 and (sys.argv[1]=="help" or sys.argv[1]=="-help" or sys.argv[1]=="--help" or sys.argv[1]=="-h"):
        usage()
        sys.exit(0)
    for idx, arg in enumerate(sys.argv):
        if ' ' in arg:  # to preserve spaces between "comas"
            sys.argv[idx] = '"%s"' % sys.argv[idx]
    if n >= 2:
        mode = sys.argv[1]
    else:
        mode = "all"

    # if not ensureGit():
    #     sys.exit(-1)

    buildConfig = Config(askUser)
    buildConfig.read()

    if mode == "cleanAll":
        print("WARNING: This will DELETE ALL content from src and build")
        print("         Notice that if you have unpushed changes, \n"
              "           they will be deleted.\n")
        print("Are you sure you want to do this? (YeS/No) -case sensitive-")
        yesno = input()
        if yesno == "YeS":
            print("Cleaning everything")
            cleanSources()
            cleanBinaries()
        else:
            print("Nothing cleaned")
            if yesno.lower()=="yes":
                print("Pay attention to capital letters of YeS")
    elif mode == "get_dependencies":
        getDependencies()
    elif mode == "cleanBin":
        cleanBinaries()
    elif mode == "version":
        buildDir = 'build'
        shortFlag = ''
        for arg in sys.argv[2:]:
            if arg == '--short':
                shortFlag = '--short'
            elif arg.startswith('dir='):
                buildDir = arg[4:]
        versionBin = "%s/bin/xmipp_version" % buildDir
        envSetting = "%s/xmipp.bashrc" % buildDir
        if not (os.path.isfile(versionBin) and os.path.isfile(envSetting)):
            print("Build not found...")
        else:
            runJob(". %s ; %s %s" % (envSetting, versionBin, shortFlag),
                   show_command=False)
    elif mode == "get_devel_sources":
        branch = None if n==2 else sys.argv[2]
        getSources(branch)
    elif mode == "config":
        buildConfig.create()
    elif mode == "check_config":
        if not buildConfig.check():
            print(red("\nCheck failed! Something wrong with the configuration.\n"))
            sys.exit(1)
    elif mode == "compile":
        Nproc = 8 if n < 3 else sys.argv[2]
        ok = compile(Nproc)
        module = 'Xmipp'
        if ok:
            print("\n"
                  "  * %s have been successfully compiled * \n"
                  "    > > > Don't forget to install! < < <   \n\n"
                  % module)
        else:
            print(red("\nSome error occurred during the compilation\n"))
            sys.exit(1)
    elif mode == "compileAndInstall":
        Nproc = 8
        dir = "build"
        if n > 2:
            for arg in sys.argv[2:]:
                if arg.isdigit() or arg.startswith('N='):
                    Nproc = arg
                else:
                    dir = arg
        ok = compile(Nproc)
        ok = ok and install(dir)
        if not ok:
            print(red("\nSome error occurred...\n"))
            sys.exit(1)
    elif mode == "install":
        if n == 3:
            dir = sys.argv[2]
        else:
            dir = "build"
        install(dir)
    elif mode == "get_models":
        modelsDir = 'build' if n==2 else sys.argv[2]
        downloadDeepLearningModels(modelsDir, dedicatedMode=True)
    elif mode == "test" or mode == "tests":
        runTests(sys.argv[2:])
    elif mode == "all":
        Nproc = 8
        branch = ''
        buildDir = 'build'
        for arg in sys.argv[2:]:
            if arg.startswith("N="):
                Nproc = int(arg[2:])
            elif arg.startswith("br="):
                branch = arg[3:]
            elif arg.startswith("dir="):
                buildDir = arg[4:]
            else:
                usage("Unknown %s argument"%arg)
                sys.exit(1)

        # create config if not there
        if not os.path.isfile(Config.FILE_NAME):
            buildConfig.create()
        else:
            print(blue("'%s' detected." % Config.FILE_NAME))
        # HACK: re-read it from file to resolve paths
        buildConfig.read()
        ok = (buildConfig.check()
            and downloadDeepLearningModels(buildDir)
            and getDependencies()
            and getSources(branch)
            and compile(Nproc)
            and install(buildDir))
        if ok:
           sys.exit(0)
        else:
           sys.exit(1)
    elif mode == "create_devel_paths":
        if n == 3:
            dir = sys.argv[2]
        else:
            dir = "."
        writeDevelPaths(dir)
    elif mode == "git":
        ensureGit(True)
        runJob("(cd src/xmippCore; git %s)"%" ".join(sys.argv[2:]))
        runJob("(cd src/xmipp; git %s)"%" ".join(sys.argv[2:]))
        runJob("(cd src/xmippViz; git %s)"%" ".join(sys.argv[2:]))
        runJob("(cd src/scipion-em-xmipp; git %s)"%" ".join(sys.argv[2:]))
    elif mode == "gitConfig":
        ensureGit(True)
        runJob("sed -i 's/https:\/\/github.com\//git@github.com:/g' src/xmippCore/.git/config")
        runJob("sed -i 's/https:\/\/github.com\//git@github.com:/g' .git/config")
        runJob("sed -i 's/https:\/\/github.com\//git@github.com:/g' src/xmippViz/.git/config")
        runJob("sed -i 's/https:\/\/github.com\//git@github.com:/g' src/scipion-em-xmipp/.git/config")
    elif mode == 'addModel':
        update = False
        if not (n == 4 or (n == 5 and sys.argv[4] == '--update') or (n == 3 and sys.argv[2] == '--help')):
            print("Incorrect number of parameters.\n")
            usage()
            sys.exit(1)
        addDeepLearninModel(*sys.argv[2:])
    elif mode == 'tar':
        if len(sys.argv) < 3:
            runJob("scripts/tar.py --help")
            sys.exit(0)
        ver = XMIPP_VERSION
        br = 'master'
        mode = sys.argv[2]
        debugFlag = ''
        for arg in sys.argv[3:]:
            if arg.startswith('br='):
                br = arg.split('br=')[1]
            if arg.startswith('v='):
                ver = arg.split('v=')[1]
            if arg.lower() == 'debug':
                debugFlag = 'debug'
        runJob("scripts/tar.py %s %s %s %s" % (mode, ver, br, debugFlag))

    else:
        usage(" -> option not found <- \n")


